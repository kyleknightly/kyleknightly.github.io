<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Math and Living Things</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/javascript">
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:wght@400;700&display=swap" rel="stylesheet">
</head>
<body>
    <header>
        <h1>Math and Living Things</h1>
        <h4>An Exploration of Mathematical Biology</h4>
        <p>Kyle Knightly</p>
    </header>
    <section id="introduction">
        <h2>Introduction</h2>
        <p>I do not wish to pretend expertise in any of these fields, but rather to suspend my ignorance and try to find some connections between them in the meantime. I am writing this as an exploration, and I welcome and expect corrections on my explanations and speculations. However, I also aim for this paper to be welcoming to those who shy away from a paper as soon as mathematics makes its first appearance–my job is just to share my excitement about math and its connection with living things. I will begin by explaining fairly simple concepts partially to keep the larger subject from slipping out from beneath me, but also to establish a method of building an understanding of the more complicated topics. Some of these topics are modeled after nature, elegant explanations of natural phenomena. Others are abstract, where the math was put first and allowed to think freely.</p>
    </section>
    <section id="golden_spirals">
        <h2>Golden Spirals</h2>
        <p>To learn how to discover connections between mathematics and nature, I’ll begin with what is probably the most famous example: the golden spiral. Pretend for a moment that you’ve never seen or heard of golden spirals before, and that you don’t know anything about the golden ratio. A good question to ask yourself is “what makes this form special?” The first observation you might make is that the golden spiral is self-similar. If you zoom in or out, nothing really changes. But if you keep looking you’d soon find there are many other self-similar spirals. The golden spiral is just one of a larger set with that property, the logarithmic spirals (fig. 1).</p>
        <p>So, what makes this <i>particular</i> logarithmic spiral special? One answer could be that it isn’t special–there are many non-golden logarithmic spirals in nature. But to faithfully attempt to answer the question we should try to precisely define a golden spiral, and here’s my best attempt: a golden spiral is a logarithmic spiral with a growth factor of $ \frac{1+\sqrt{5}}{2} $. </p>
        <p>Stay with me, and try not to worry about what exactly a growth factor of a logarithmic spiral is, for now we’d better worry about what is special about this specific number. We call this number $\varphi$, “phi”,  but what is it really? Luckily there is a beautiful answer. Imagine two line segments, a and b. If you make their lengths so that 
            $ a:b = (a+b):a $
            , then 
            $ \frac{a}{b}=\varphi $
            . In other words, try making two numbers where the ratio between them is the same as the ratio between their sum and the larger number. Now, imagine turning those line segments into squares 
            $ A $ and $ B $, 
            extending their lengths downward. You’d find an empty rectangle under square $b$ with dimensions in proportion
            $ a:b $
            . Keep going, filling in these remaining rectangles with squares leaving the center empty (fig. 2).
            </p>
        <p>And there is surprising beauty; it is becoming clear that the self similarity of the golden curve supersedes that of any other logarithmic curve, it is the self-similarest! This is a very important discovery, because self-similarity might have seemed to be a binary trait, but it is more comparable to being infinite, where some infinities are larger than others. Connecting certain vertices smoothly inward yields the golden spiral. As promised, we now have a logarithmic spiral with a growth factor of 
            $ \varphi $
            . We also now have a <i>real</i> idea of what a logarithmic spiral’s growth factor is, which I think is more useful than a purely mathematical definition.
        </p>
        <p>So, if golden spirals are particularly self-similar, we can rephrase our earlier question as “what is special about self-similarity?”. Imagine you have one of those inner rectangles with dimensions 
            $ 1:\varphi $
            . You could then build outward with squares, creating that same pattern as before, forever. If you did have the infinite sequence of squares, any single square you chose would be topologically identical. So, if we think of our placement of proportional squares as a growth algorithm, it is now clear why this type of structure is so inherent to living things. A single, simple growth algorithm can be fetched at any state of the growth sequence.
        </p>
    </section>
    <section id="cells_as_machines">
        <h2>Cells as Machines</h2>
        <p>That line of reasoning is very interesting, but equally dangerous. Obviously there is no simple growth algorithm that living things fetch, so before we continue down this road we should recognize its failures. Mechanistic characterization of biology is extremely pronounced and lives at the center of biology’s most active fields such as cancer research (Hanahan et al. 2000). This idea has issues beyond oversimplification, it mischaracterizes biological components from the ground up, leading to a framework of studying biology that is unproductive and misleading (Nicholson 2019).</p>
        <p>While mathematical biology, the attempt to model living things with mathematical formulas and models, might seem to be an even more extreme case of this fallacy, it is important to pinpoint the specific issue with the machine conception of the cell, and I’ll give you a hint: it certainly isn’t simplification. It really lies in what a machine is–machines are defined by their parts and how they come together, they can be constructed faithfully with a set of instructions. Machines are also highly specialized and constrained in their performance. Machines may also be interrupted, you can take them apart, put them back together, and they should continue moving as before. The contradiction between cells and machines as a metaphor can be boiled down to two traits of cells, their self-organization and continuous undefined function (Nicholson 2019). Additionally, I would argue that a cell cannot be constructed faithfully with a set of instructions. Certainly you’d need more instructions than DNA, but if you reach a point where the instructions required are the positions and velocities of all quantum particles in the cell, we’re really going to have a hard time building it (see discussions on free will and quantum physics for smarter people’s thoughts on this).</p>
        <p>Mathematical biology certainly has a responsibility to be cautious of these types of fallacies, but it seems to be a promising way out of this misdirection. Our discovery about golden spirals wasn’t really about how living things work, it was about why they are the way they are. Idealization is a clear necessity to science, but it must be done cautiously and for the sake of discovery. When those ideals are too central to our actual perceptions our research can mander down suboptimal paths for decades on end.</p>
    </section>
    <section id="bifurcation">
        <h2>Bifurcation</h2>
        <p>The logistic map is another example of mathematics that is central to biology, and can be looked at in quite the same way that we analyzed golden spirals. If you have a population with some rate of reproduction, which is proportional to the population size, and some rate of starvation, proportional to the population’s carrying capacity. So, to find a population 
            $ x_{n+1} $
             as a proportion of carrying capacity, you could multiply the previous iteration’s population by some growth rate, 
            $ r $
            , and constrain the maximum possible population with the term 
            $ (1-x) $
            . This equation, 
            $ x_{n+1} = rx_n(1-x_n) $
            , is the logistic map. And with different growth rates and initial populations, you can watch as populations evolve over time and settle on equilibria (May 1976). Initial population 
            $x_0$
             has no effect on the end behaviors of a population, so for our purposes we can select 
            $ x_0 = 0.3 $
             for consistency. So, let's investigate the equilibria for a few values of $r$.
        </p>
        
        <!-- Div to hold the plot -->
        <div id="logistic-map" style="width:100%;max-width:700px;height:500px;"></div>
        <!-- Slider to control r -->
        <div style="text-align: center; margin-top: 10px;">
            <input type="range" id="r-slider" min="0" max="4" step="0.01" value="3.0" oninput="updateGraph()" style="width: 50%; max-width: 400px;">
            <br>
            <span id="r-value">r = 3.00</span>
        </div>

        <script>
            // Function to generate logistic map values
            function logisticMap(r, x0, iterations) {
                let x = x0;
                let values = [x];
                for (let i = 1; i < iterations; i++) {
                    x = r * x * (1 - x);
                    values.push(x);
                }
                return values;
            }

            // Initial parameters
            let r = 1.0;
            let x0 = 0.3; // Initial value of x
            let iterations = 30;

            // Function to update the graph
            function updateGraph() {
                r = parseFloat(document.getElementById("r-slider").value);
                document.getElementById("r-value").textContent = `r = ${r.toFixed(2)}`;

                let yValues = logisticMap(r, x0, iterations);
                let xValues = Array.from({length: iterations}, (_, i) => i + 1);

                let trace = {
                    x: xValues,
                    y: yValues,
                    mode: 'lines+markers',
                    type: 'scatter'
                };

                let layout = {
                    xaxis: {title: {
                            text: 'n'  // LaTeX expression for the axis title
                        }},
                    yaxis: {title: 'x',
                            range: [0, 1]},
                    font: {
                        family: "'EB Garamond', serif", // Apply this font family to all text elements
                        size: 14,
                        color: '#333333'},
                    margin: { t: 50 }
                };

                Plotly.newPlot('logistic-map', [trace], layout);
            }

            // Initial plot
            updateGraph();
            // Add event listeners to clickable terms
            document.addEventListener('DOMContentLoaded', function () {
                document.querySelectorAll('.r-link').forEach(function(element) {
                    element.addEventListener('click', function() {
                        const rValue = parseFloat(this.getAttribute('data-r'));
                        document.getElementById('r-slider').value = rValue; // Change slider value
                        updateGraph(); // Update the graph
                    });
                });
            });
        </script>
        <p>At <span class="r-link" data-r="1.0">$r=1$</span> the growth rate is so small that the population dies out rather quickly. At <span class="r-link" data-r="2.0">$r=2$</span> it quickly settles at $x=0.5$, and stays there iteration after iteration. At <span class="r-link" data-r="3.0">$r=3$</span> there is an interesting balance between growth and death, and iterations bounce back and forth between two values. Then, at <span class="r-link" data-r="3.47">$r=3.47$</span> there is another bifurcation, there are 4 relatively stable values that the population bounces around between predictably. But even just $0.1$ units higher, at <span class="r-link" data-r="3.57">$r=3.57$</span>, that stability begins to dissolve. And at <span class="r-link" data-r="4.0">$r=4$</span> the pattern is completely lost, and there is no equilibrium at all. In fact, early computers used to use this function to generate pseudorandom numbers. Critically, though, this data will always be the same no matter how many times you run the simulation–these numbers are not actually random at all. I strongly recommend that you play around with this, scrub through the values and try to find some interesting behaviors. There is clearly something interesting going on with equilibria in the logistic map equation, so let’s try plotting the numbers that $x$ “settles” on against different values of $r$.</p>
        <p>This is the logistic map (fig. 4), and it is a fractal pattern riddled with areas of seemingly random complexity and sudden order. Comparing this to our data, we see a single equilibrium below <span class="r-link" data-r="3.0">$r=3$</span>, and then two equilibria until <span class="r-link" data-r="3.5">$r=3.5$</span>, where the chaos begins.</p>
        <p>The logistic map, and chaotic bifurcation patterns in general, exist as clearly in nature as the golden spiral. In real organism populations as well as thermodynamics, fluid dynamics, and cardiology there have been clearly demonstrated bifurcation patterns that lead to chaotic behavior, much like the logistic map (Garfinkel et al. 1992, Libchaber et al. 1982, Shaw 1984). For example, in a famous experiment it was shown that as a rabbit heart undergoes fibrillation, there is a period doubling in heartbeat that eventually leads to death. Using chaos theory, researchers determined optimal times to apply electrical shocks to the rabbits, returning their heartbeats to periodicity with some success (Garfinkel et al. 1992).
        </p>
    </section>
    <section id="patterns">
        <h2>Patterns</h2>
        <h3>Reaction-Diffusion</h3>
        <p>Alan Turing was a mathematician and computer scientist famous for his contributions to cryptography and historic role in World War II. But two years before his death, he wrote an important paper in the field of mathematical biology, “The Chemical Basis of Morphogenesis”. He was inspired by D’Arcy Thompson’s book, <i>On Growth and Form</i>, which connected mathematics to evolution, and argued for consideration of physical laws in the field of biology as a whole. Turing wondered if the same thing could be done with chemistry, if there were principles of chemical reactions that govern how organisms form (Ball 2015).</p>
        <p>He describes a simplified embryo containing two morphogens, substances with varying physical and chemical properties that interact to determine the physical form of an organism. This definition is intentionally vague, and encapsulates genes, hormones, and even skin pigments (Turing 1952). He does well to describe the long list of limitations of this simplification, but carries on describing how certain properties of these morphogens could result in novel reaction diffusion patterns. The mathematics behind this type of interaction is precise, but quite the opposite to the logistic map in that the equations are complex, and the visual is intuitive (fig. 5).</p>
        <p>This particular simulation uses the Gray-Scott model, a derivative of Turing’s equation developed in the Chemical Basis of Morphogenesis. Turing's model is more general and versatile, capable of producing a wider range of patterns. The Gray-Scott model, being a simplification, is computationally less expensive and has been widely used for simulating pattern formation in reaction-diffusion systems.</p>
        <p>Turing developed the following partial differential equations:
            $$ \frac{\partial u}{\partial t} = D_u \nabla^2 u + f(u,v) $$
            $$ \frac{\partial v}{\partial t} = D_v \nabla^2 v + g(u,v) $$
            where $u$ is an autocatalyst (self-producer) and $v$ is an inhibitor, and the functions $f$ and $g$ determine how the neighboring concentration of one substance influences the other, and the laplacian ($\nabla^2$) terms are similar to a convolution (like a smudging) of a particle of the substance, with the result dependent on the neighboring particles’ identities. The Gray-Scott model primarily is distinct by the chosen behavior of the autocatalyst and inhibitor. In Turing’s equations, the autocatalyst promotes growth of both substances, and the inhibitor inhibits the growth of both substances. In the Gray-Scott model the autocatalyst promotes its own growth, consuming the inhibitor. The inhibitor is added at rate r and the autocatalyst must be removed at rate k to keep the reaction going. The mathematics look quite similar:
            $$ \frac{\partial u}{\partial t} = D_u \nabla^2 u - uv^2 + F(1-u) $$
            $$ \frac{\partial v}{\partial t} = D_v \nabla^2 v + uv^2 - (F+k)v $$
            where the values of r and k can easily be altered to drastically change the behavior of the system, making these equations more approachable to build an understanding.
        </p>    
        <h3>Conway’s Game of Life</h3>
        <p>If partial differential equations are outside of your mathematical comfort zone, there is an interestingly related but far simpler model: Conway’s Game of Life. This game can be described with three rules (different rule sets, often with four rules, describe the same game in slightly different ways, so if these are not intuitive the other explanations may be helpful):</p>
        <ol>
            <li>A living cell with less than two neighbors dies (starvation)</li>
            <li>A living cell with more than three neighbors dies (overpopulation)</li>
            <li>A dead cell with three neighbors comes to life (reproduction)</li>
        </ol>
        <p>This game is extremely computationally cheap, unlike reaction-diffusion, and you can play it yourself quite easily with graph paper. This simple game yields surprising complexity, such as gliders that move across the array forever, or growing complexes that never stop.</p>
        This particular set of cells (fig. 6) would die out in the next iteration, but when you play the game on an infinite array and begin with more complex conditions the similarities to reaction-diffusion become more visual, especially at low values of $r$ under the Gray-Scott model.
        <h3>Turing Completeness</h3>
        <p>Reaction-diffusion and the Game of Life differ in that reaction-diffusion reaches a sort of equilibrium, even if the substances never stop moving or interacting. Conway’s Game of Life is different, and you may find that on the millionth iteration the entire infinite plane of cells fizzles out and dies completely. The Game of Life is known to be a “Turing complete” system. This property of the Game of Life was demonstrated by Paul Rendell when he created a pattern known as a "universal constructor" that can be used to simulate any arbitrary cellular automaton, making the Game of Life Turing complete (Rendell 2011). To grossly simplify what this means, the Game of Life can be used to simulate any other Turing machine, which is a simple yet powerful abstract computer. Reaction-diffusion on the other hand is not known to be Turing complete. This hasn’t been proved one way or another, but the stability and predictability of reaction-diffusion is characteristically unlike a Turing machine.</p>
        <p>Turing completeness is particularly important because of how it relates to our machine conception of the cell. Recall that the two traits of cells that make them non-mechanistic is their self-organization and continuous, undefined function. A Turing complete machine has a very defined function, and runs on iterations of instructions, not continuously. What makes reaction-diffusion promising isn’t that it might be Turing complete, it’s that it might actually be Turing incomplete. Reaction-diffusion is a continuous function, despite being computed in steps. If it was possible to compute with reaction-diffusion, it would be more biological than the computation of Turing machines (although I must admit, who knows what “more biological” even means in this context?).</p>
    </section>
    <section id="conclusion">
        <h2>Conclusion</h2>
        <p>The pattern of thought we first used to understand golden spirals–beginning with understanding the behavior of the mathematics at the simplest possible level, and then exploring the edge cases, where the definitions fail or bleed into others, or where properties emerge and fade away–has useful application in the exploration of other mathematical patterns that are exhibited by living things. While some of these patterns clearly exhibit order, many are chaotic with complex behavior. And yet, the field of chaos theory, and other seemingly obscure topics in mathematics, bring clarity to these situations.</p>
        <p>Impressive progress in the field of mathematical biology has come from preliminary exploration of other fields, such as physics with Thompson or chemistry with Turing. Surprisingly there don’t seem to have been any real breakthroughs in the past few decades, which to me is a sign that the field is ripe for another expansion into topics in chaos theory, computer science, modern physics, modern mathematics, and so on. I see this as the most promising frontier in modern biology, and yet it is largely out of the limelight of funding and research efforts.</p>
    </section>
    <section id="acknowledgements">
        <h2>Acknowledgements</h2>
        <p>I would like to sincerely thank Dr. Michael Gustin and Dr. Kathleen Beckingham for their invaluable insight and help proofreading this paper.</p>
    </section>
    <section id="references">
        <h2>References</h2>
        <ul>
            <li>Ball, P. (2015). Forging patterns and making waves from biology to geology: a commentary on Turing (1952) ‘The chemical basis of morphogenesis’ Phil. Trans. R. Soc. B3702014021820140218 http://doi.org/10.1098/rstb.2014.0218</li>
            <li>Garfinkel, A., Spano ML, Ditto WL, Weiss JN. Controlling cardiac chaos. Science  28 Aug 1992: Vol. 257, Issue 5074, pp. 1230-1235 DOI: 10.1126/science.1519060</li>
            <li>Hanahan, D., & Weinberg, R. A. (2000). The Hallmarks of Cancer. In Cell (Vol. 100, Issue 1, pp. 57–70). Elsevier BV. https://doi.org/10.1016/s0092-8674(00)81683-9</li>
            <li>Libchaber A., Laroche C., Fauve S. (1982). Period doubling cascade in mercury, a quantitative measurement. Journal de Physique Lettres, 43 (7), pp.211-216. ff10.1051/jphyslet:01982004307021100ff. ffjpa00232033f</li>
            <li>May, R. (1976). Simple mathematical models with very complicated dynamics. Nature 261, 459–467 . https://doi.org/10.1038/261459a0</li>
            <li>May, R. M., Wishart, D. M. G., Bray, J., & Smith, R. L. (1987). Chaos and the Dynamics of Biological Populations [and Discussion]. Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences, 413(1844), 27–44. http://www.jstor.org/stable/2398225</li>
            <li>Nicholson, DJ. (2019). Is the cell really a machine? J Theor Biol. Sep 21;477:108-126. doi: 10.1016/j.jtbi.2019.06.002. Epub 2019 Jun 4. PMID: 31173758.</li>
            <li>Rendell, P.W. (2011). A Universal Turing Machine in Conway's Game of Life. 2011 International Conference on High Performance Computing & Simulation, 764-772.</li>
            <li>Shaw, R. (1984). The Dripping Faucet As A Model Chaotic System.</li>
            <li>Sims, K. (2022). RD Tool</li>
            <li>Turing, A. (1952). The chemical basis of morphogenesis. Phil. Trans. R. Soc. Lond. B 237, 37–72. doi:10.1098/rstb.1952.0012</li>
            
        </ul>
    </section>
    
    <!-- Additional sections follow the same structure -->
    
</body>
</html>
